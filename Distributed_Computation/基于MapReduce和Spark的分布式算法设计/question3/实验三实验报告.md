# 实验三

## 实验内容

输入文件为学生成绩信息，包含了必修课与选修课成绩，格式如下： 

班级1, 姓名1, 科目1, 必修, 成绩1 <br>班级2, 姓名2, 科目1, 必修, 成绩2 <br>班级1, 姓名1, 科目2, 选修，成绩3 <br>………., ………, ………, ………   <br> 编写一个Spark程序，同时实现如下功能： 1. 计算每个学生必修课的平均成绩。 2. 统计学生必修课平均成绩在：90~100,80~89,70~79,60~69和60分以下这5个分数段的人数。 

### commands

```powershell
cd ./share/question3

hadoop fs -put ./grades.txt / 

spark-submit spark_avg.py

hadoop fs -ls /user/root/result1
hadoop fs -cat /user/root/result1/part-00000
hadoop fs -rm -r 

hadoop fs -ls /user/root/result2
hadoop fs -cat /user/root/result2/part-00000
hadoop fs -rm -r 
```



## 设计思想

​	任务一要求计算每个学生必修课的平均成绩，首先通过RDD转换算子filter过滤掉选修相关的数据，再将key-value设置为学生名字与其必修课成绩，最后进行取平均。

​	任务二要求统计学生在五个分数段的人数，首先将学生划分给不同的分数段并将分数段作为key值，再统计每个分数段人数。

```python
from pyspark import SparkConf, SparkContext

def map_func(x):
    s = x.split(",")
    return s[1], int(s[4]) #name score

def map_func1(x):
    if 90 <= x <= 100:
        return "90~100", 1
    if 80 <= x <= 89:
        return "80~89", 1
    if 70 <= x <= 79:
        return "70~79", 1
    if 60 <= x <= 69:
        return "60~69", 1
    if x < 60:
        return "<60:", 1

# 配置信息
conf = SparkConf().setMaster("local").setAppName("avgcount")
sc = SparkContext(conf=conf)

# 输入数据集
textData = sc.textFile("/grades.txt") # RDD创建算子
# splitData = textData.flatMap(lambda line: line.split(","))
lines = textData.filter(lambda line: "必修" in line).map(lambda x: map_func(x)) # RDD转换算子：filter

avgData = lines.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])).mapValues(
    lambda x: int(x[0] / x[1])) #mapValues 仅对k-v键值对的value进行操作
#mapValues方法调用结束后k-v对->(name:[score,1])    reduceByKey:(name:[sum_score,num_subject])  mapValues:(name:avg_score)
avgData.saveAsTextFile("result1")

fData = avgData.map(lambda x: map_func1(x[1])).reduceByKey(lambda x, y: (x + y))
#map:("分数段":1) reduceBykey:("分数段":nums)

fData.saveAsTextFile("result2")
```



## 主要步骤和实验结果

### 主要步骤

切换到pyspark程序所在目录：

![image-20220614123204233](https://cdn.jsdelivr.net/gh/mistletoe1222/img/imgs/202206141232321.png)

运行pyspark程序：

![image-20220614123228256](https://cdn.jsdelivr.net/gh/mistletoe1222/img/imgs/202206141232298.png)

### 实验结果

任务一，部分结果展示：

![image-20220612094903859](https://cdn.jsdelivr.net/gh/mistletoe1222/img/imgs/202206120949902.png)

任务二，结果展示：

![image-20220612094934075](https://cdn.jsdelivr.net/gh/mistletoe1222/img/imgs/202206120949128.png)

## 遇到的问题及解决方法



## 心得体会

